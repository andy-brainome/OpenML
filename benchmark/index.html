



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../">
      <meta name="generator" content="mkdocs-0.17.3, mkdocs-material-2.6.0">
    
    
      
        <title>Benchmarking - OpenML Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.aa3de92b.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.792431c1.css">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
      <link rel="stylesheet" href="../css/extra.css">
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <a href="#benchmarking-suites" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="OpenML Documentation" class="md-header-nav__button md-logo">
          
            <i class="md-icon">school</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                OpenML Documentation
              </span>
              <span class="md-header-nav__topic">
                Benchmarking
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/openml/OpenML/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href=".." title="Bootcamp" class="md-tabs__link md-tabs__link--active">
          Bootcamp
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../APIs/" title="APIs" class="md-tabs__link">
          APIs
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../developers/" title="Developers" class="md-tabs__link">
          Developers
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon">school</i>
      
    </span>
    OpenML Documentation
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/openml/OpenML/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1" checked>
    
    <label class="md-nav__link" for="nav-1">
      Bootcamp
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        Bootcamp
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href=".." title="Get started" class="md-nav__link">
      Get started
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-2" type="checkbox" id="nav-1-2">
    
    <label class="md-nav__link" for="nav-1-2">
      Integrations
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-2">
        Integrations
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../sklearn/" title="scikit-learn" class="md-nav__link">
      scikit-learn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../mlr/" title="mlr" class="md-nav__link">
      mlr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Weka/" title="WEKA" class="md-nav__link">
      WEKA
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../MOA/" title="MOA" class="md-nav__link">
      MOA
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-3" type="checkbox" id="nav-1-3">
    
    <label class="md-nav__link" for="nav-1-3">
      Community
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-3">
        Community
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Contributing/" title="How to contribute" class="md-nav__link">
      How to contribute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Communication-Channels/" title="Communication Channels" class="md-nav__link">
      Communication Channels
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Core-team/" title="Core team" class="md-nav__link">
      Core team
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        Benchmarking
      </label>
    
    <a href="./" title="Benchmarking" class="md-nav__link md-nav__link--active">
      Benchmarking
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#software-interfaces" title="Software interfaces" class="md-nav__link">
    Software interfaces
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-openml-benchmark-suites" title="Using OpenML Benchmark Suites" class="md-nav__link">
    Using OpenML Benchmark Suites
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#listing-the-benchmark-suites" title="Listing the benchmark suites" class="md-nav__link">
    Listing the benchmark suites
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fetching-details" title="Fetching details" class="md-nav__link">
    Fetching details
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#running-and-sharing-benchmarks" title="Running and sharing benchmarks" class="md-nav__link">
    Running and sharing benchmarks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retrieving-runs-on-a-benchmarking-suites" title="Retrieving runs on a benchmarking suites:" class="md-nav__link">
    Retrieving runs on a benchmarking suites:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-new-benchmark-suites" title="Creating new benchmark suites" class="md-nav__link">
    Creating new benchmark suites
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#updating-a-benchmark-suite" title="Updating a benchmark suite" class="md-nav__link">
    Updating a benchmark suite
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-code-examples-and-use-cases" title="Further code examples and use cases" class="md-nav__link">
    Further code examples and use cases
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#list-of-benchmarking-suites" title="List of benchmarking suites" class="md-nav__link">
    List of benchmarking suites
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openml-cc18" title="OpenML-CC18" class="md-nav__link">
    OpenML-CC18
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openml100" title="OpenML100" class="md-nav__link">
    OpenML100
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#need-help" title="Need help?" class="md-nav__link">
    Need help?
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../altmetrics/" title="Altmetrics" class="md-nav__link">
      Altmetrics
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../terms/" title="Terms" class="md-nav__link">
      Terms
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      APIs
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        APIs
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../APIs/" title="OpenML APIs" class="md-nav__link">
      OpenML APIs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2" type="checkbox" id="nav-2-2">
    
    <label class="md-nav__link" for="nav-2-2">
      REST
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-2">
        REST
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../REST-tutorial/" title="Tutorial" class="md-nav__link">
      Tutorial
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../REST-API/" title="API Reference" class="md-nav__link">
      API Reference
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-3" type="checkbox" id="nav-2-3">
    
    <label class="md-nav__link" for="nav-2-3">
      Java
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-3">
        Java
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Java-guide/" title="Tutorial" class="md-nav__link">
      Tutorial
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-4" type="checkbox" id="nav-2-4">
    
    <label class="md-nav__link" for="nav-2-4">
      Python
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-4">
        Python
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Python-start/" title="Get started" class="md-nav__link">
      Get started
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python-guide/" title="User guide" class="md-nav__link">
      User guide
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python-examples/" title="Examples" class="md-nav__link">
      Examples
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python-API/" title="API Reference" class="md-nav__link">
      API Reference
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python-contributing/" title="Contributing" class="md-nav__link">
      Contributing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python-changelog/" title="Changelog" class="md-nav__link">
      Changelog
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-5" type="checkbox" id="nav-2-5">
    
    <label class="md-nav__link" for="nav-2-5">
      R
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-5">
        R
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../R-guide/" title="Tutorial" class="md-nav__link">
      Tutorial
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../R-API/" title="API Reference" class="md-nav__link">
      API Reference
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-6" type="checkbox" id="nav-2-6">
    
    <label class="md-nav__link" for="nav-2-6">
      .NET (C#)
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-6">
        .NET (C#)
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../NET-API/" title="Tutorial" class="md-nav__link">
      Tutorial
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Developers
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Developers
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../developers/" title="Welcome" class="md-nav__link">
      Welcome
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../OpenML-Docs/" title="Editing Documentation" class="md-nav__link">
      Editing Documentation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Local-Installation/" title="Local Installation" class="md-nav__link">
      Local Installation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-4" type="checkbox" id="nav-3-4">
    
    <label class="md-nav__link" for="nav-3-4">
      API development
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-4">
        API development
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Client-API-Standards/" title="Client API Standards" class="md-nav__link">
      Client API Standards
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../API-rules/" title="Server API Development" class="md-nav__link">
      Server API Development
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../API-Authentication-and-User-types/" title="User Authentication" class="md-nav__link">
      User Authentication
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-5" type="checkbox" id="nav-3-5">
    
    <label class="md-nav__link" for="nav-3-5">
      Data handling
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-5">
        Data handling
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Data-Formats/" title="Data Formats" class="md-nav__link">
      Data Formats
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Data-Repositories/" title="Data Repositories" class="md-nav__link">
      Data Repositories
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Data-collections/" title="Data collections" class="md-nav__link">
      Data collections
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-6" type="checkbox" id="nav-3-6">
    
    <label class="md-nav__link" for="nav-3-6">
      Backend (PHP)
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-6">
        Backend (PHP)
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../WebApp-(PHP)/" title="WebApp" class="md-nav__link">
      WebApp
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../URL-Mapping/" title="URL Mapping" class="md-nav__link">
      URL Mapping
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-7" type="checkbox" id="nav-3-7">
    
    <label class="md-nav__link" for="nav-3-7">
      Backend (Java)
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-7">
        Backend (Java)
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Java-App/" title="Java Backend" class="md-nav__link">
      Java Backend
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Helper-functions/" title="Helper functions" class="md-nav__link">
      Helper functions
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#software-interfaces" title="Software interfaces" class="md-nav__link">
    Software interfaces
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-openml-benchmark-suites" title="Using OpenML Benchmark Suites" class="md-nav__link">
    Using OpenML Benchmark Suites
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#listing-the-benchmark-suites" title="Listing the benchmark suites" class="md-nav__link">
    Listing the benchmark suites
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fetching-details" title="Fetching details" class="md-nav__link">
    Fetching details
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#running-and-sharing-benchmarks" title="Running and sharing benchmarks" class="md-nav__link">
    Running and sharing benchmarks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retrieving-runs-on-a-benchmarking-suites" title="Retrieving runs on a benchmarking suites:" class="md-nav__link">
    Retrieving runs on a benchmarking suites:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-new-benchmark-suites" title="Creating new benchmark suites" class="md-nav__link">
    Creating new benchmark suites
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#updating-a-benchmark-suite" title="Updating a benchmark suite" class="md-nav__link">
    Updating a benchmark suite
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-code-examples-and-use-cases" title="Further code examples and use cases" class="md-nav__link">
    Further code examples and use cases
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#list-of-benchmarking-suites" title="List of benchmarking suites" class="md-nav__link">
    List of benchmarking suites
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openml-cc18" title="OpenML-CC18" class="md-nav__link">
    OpenML-CC18
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openml100" title="OpenML100" class="md-nav__link">
    OpenML100
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#need-help" title="Need help?" class="md-nav__link">
    Need help?
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/openml/OpenML/edit/master/docs/docs/benchmark.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="benchmarking-suites">Benchmarking suites<a class="headerlink" href="#benchmarking-suites" title="Permanent link">&para;</a></h1>
<p>Machine learning research depends on objectively interpretable, comparable, and reproducible algorithm benchmarks. OpenML aims to facilitate the creation of curated, comprehensive <em>suites</em> of machine learning tasks, covering precise sets of conditions.</p>
<p>Seamlessly integrated into the OpenML platform, benchmark suites standardize the setup, execution, analysis, and reporting of benchmarks. Moreover, they make benchmarking a whole lot easier:</p>
<ul>
<li>all datasets are uniformly formatted in standardized data formats</li>
<li>they can be easily downloaded programmatically through <a href="../APIs">APIs and client libraries</a></li>
<li>they come with machine-readable <a href="https://www.openml.org/search?type=measure&amp;q=+measure_type%3Adata_quality">meta-information</a>, such as the occurrence of missing values, to train algorithms correctly</li>
<li>standardized train-test splits are provided to ensure that results can be objectively compared</li>
<li>results can be shared in a reproducible way through the <a href="../APIs">APIs</a></li>
<li>results from other users can be easily downloaded and reused</li>
</ul>
<h2 id="software-interfaces">Software interfaces<a class="headerlink" href="#software-interfaces" title="Permanent link">&para;</a></h2>
<p>To use OpenML Benchmark suites, you can use bindings in several programming languages. These all interface with the OpenML REST API. The default endpoint for this is <code>https://www.openml.org/api/v1/</code>, but this can change when later versions of the API are released. To use the code examples below, you only need a recent version of one of the following libraries:</p>
<ul>
<li><a href="https://mvnrepository.com/artifact/org.openml/apiconnector">OpenML Java ApiConnector</a> (version <code>1.0.22</code> and up).</li>
<li><a href="https://search.maven.org/search?q=a:openmlweka">OpenML Weka</a> (version <code>0.9.6</code> and up). This package adds a Weka Integration.</li>
<li><a href="https://pypi.org/project/openml/">OpenML Python</a> (version <code>0.8.0</code> and up)</li>
<li><a href="https://cran.r-project.org/web/packages/OpenML/index.html">OpenML R</a> (version <code>1.8</code> and up)</li>
</ul>
<h2 id="using-openml-benchmark-suites">Using OpenML Benchmark Suites<a class="headerlink" href="#using-openml-benchmark-suites" title="Permanent link">&para;</a></h2>
<p>Below are walk-through instructions for common use cases, as well as code examples. These illustrations use the reference <a href="https://docs.openml.org/benchmark/#openml-cc18">OpenML-CC18</a> benchmark suite, but you can replace it with any other benchmark suite. Note that a benchmark suite is a set of OpenML <code>tasks</code>, which envelop not only a specific dataset, but also the train-test splits and (for predictive tasks) the target feature.</p>
<details class="note"><summary>Terminology and current status</summary><p>Benchmark suites are sets of OpenML tasks that you can create and manage yourself. At the same time, it is often useful to also share the set of experiments (runs) with the ensuing benchmarking results. For legacy reasons, such sets of tasks or runs are called <code>studies</code> in the OpenML REST API. In the OpenML bindings (Python, R, Java,...) these are called either <code>sets</code> or <code>studies</code>.</p><p>When benchmarking, you will probably use two types of sets:</p><ul><li>Sets of tasks. These can be created, edited, downloaded or deleted via the OpenML API. Website forms will be added soon. Also the set of underlying datasets can be easily retrieved via the API.</li><li>Sets of runs. Likewise, these can be created, edited, downloaded or deleted via the OpenML API. On the website, these are currently simply called 'studies'. Also the set of underlying tasks, datasets and flows can be easily retrieved. It is possible to link a set of runs to a benchmark study, aimed to collect future runs on that specific set of tasks. Additional information on these will be provided in a separate page.</li></ul></details><h3 id="listing-the-benchmark-suites">Listing the benchmark suites<a class="headerlink" href="#listing-the-benchmark-suites" title="Permanent link">&para;</a></h3>
<p>The current list of benchmark suites is explicitly listed on the bottom of this page. The list of all sets of tasks can also be fetched programmatically. This list includes the suite's ID (and optionally an alias), which can be used to fetch further details.</p>
<details class="note"><summary>REST (under development)</summary><p><a href="https://www.openml.org/api/v1/xml/study/list/main_entity_type/task">https://www.openml.org/api/v1/xml/study/list/main_entity_type/task</a></p><p><a href="https://www.openml.org/api_docs/#!/study/get_study_list_filters">Check out the API docs</a></p></details><details class="note"><summary>Python example (requires the development version)</summary><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">openml</span>

<span class="c1"># using the main entity type task, only benchmark suites are returned</span>
<span class="c1"># each benchmark suite has an ID, some also have an alias. These can be</span>
<span class="c1"># used to obtain the full details. </span>
<span class="n">studies</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">list_studies</span><span class="p">(</span><span class="n">main_entity_type</span><span class="o">=</span><span class="s1">&#39;task&#39;</span><span class="p">)</span>
</pre></div>
</details><details class="note"><summary>Java example</summary><div class="highlight"><pre><span></span><span class="kd">public</span> <span class="kt">void</span> <span class="nf">listBenchmarksuites</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">OpenmlConnector</span> <span class="n">openml</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OpenmlConnector</span><span class="o">();</span>
    <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">filters</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TreeMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;();</span>
    <span class="n">filters</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;status&quot;</span><span class="o">,</span> <span class="s">&quot;all&quot;</span><span class="o">);</span>
    <span class="n">filters</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;main_entity_type&quot;</span><span class="o">,</span> <span class="s">&quot;task&quot;</span><span class="o">);</span>
    <span class="n">filters</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;limit&quot;</span><span class="o">,</span> <span class="s">&quot;20&quot;</span><span class="o">);</span>
    <span class="n">StudyList</span> <span class="n">list</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">studyList</span><span class="o">(</span><span class="n">filters</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</details><details class="note"><summary>R example</summary><div class="highlight"><pre><span></span>TODO
</pre></div>
</details><h3 id="fetching-details">Fetching details<a class="headerlink" href="#fetching-details" title="Permanent link">&para;</a></h3>
<p>Using the ID or alias of a benchmark suite, you can retrieve a description and the full list of tasks and the underlying datasets.</p>
<details class="note"><summary>REST</summary><p><a href="https://www.openml.org/api/v1/xml/study/OpenML-CC18">https://www.openml.org/api/v1/xml/study/OpenML-CC18</a></p><p><a href="https://www.openml.org/api_docs/#!/study/get_study_id">Check out the API docs</a></p></details><details class="note"><summary>Python example</summary><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">openml</span>
<span class="n">benchmark_suite</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">get_study</span><span class="p">(</span><span class="s1">&#39;OpenML-CC18&#39;</span><span class="p">,</span><span class="s1">&#39;tasks&#39;</span><span class="p">)</span> <span class="c1"># obtain the benchmark suite</span>
<span class="k">for</span> <span class="n">task_id</span> <span class="ow">in</span> <span class="n">benchmark_suite</span><span class="o">.</span><span class="n">tasks</span><span class="p">:</span> <span class="c1"># iterate over all tasks</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">get_task</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span> <span class="c1"># download the OpenML task</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">task</span><span class="o">.</span><span class="n">get_X_and_y</span><span class="p">()</span> <span class="c1"># get the data</span>
</pre></div>
</details><details class="note"><summary>Java example</summary><div class="highlight"><pre><span></span><span class="kd">public</span> <span class="kt">void</span> <span class="nf">downloadDatasets</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">OpenmlConnector</span> <span class="n">openml</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OpenmlConnector</span><span class="o">();</span>
    <span class="n">Study</span> <span class="n">benchmarksuite</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">studyGet</span><span class="o">(</span><span class="s">&quot;OpenML-CC18&quot;</span><span class="o">,</span> <span class="s">&quot;tasks&quot;</span><span class="o">);</span>
    <span class="k">for</span> <span class="o">(</span><span class="n">Integer</span> <span class="n">taskId</span> <span class="o">:</span> <span class="n">benchmarksuite</span><span class="o">.</span><span class="na">getTasks</span><span class="o">())</span> <span class="o">{</span> <span class="c1">// iterate over all tasks</span>
        <span class="n">Task</span> <span class="n">t</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">taskGet</span><span class="o">(</span><span class="n">taskId</span><span class="o">);</span> <span class="c1">// download the OpenML task</span>
        <span class="c1">// note that InstanceHelper is part of the OpenML-weka package</span>
        <span class="n">Instances</span> <span class="n">d</span> <span class="o">=</span> <span class="n">InstancesHelper</span><span class="o">.</span><span class="na">getDatasetFromTask</span><span class="o">(</span><span class="n">openml</span><span class="o">,</span> <span class="n">t</span><span class="o">);</span> <span class="c1">// obtain the dataset</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</details><details class="note"><summary>R example</summary><div class="highlight"><pre><span></span><span class="kn">library</span><span class="p">(</span>OpenML<span class="p">)</span>
task.ids <span class="o">=</span> getOMLStudy<span class="p">(</span><span class="s">&#39;OpenML-CC18&#39;</span><span class="p">)</span><span class="o">$</span>tasks<span class="o">$</span>task.id <span class="c1"># obtain the list of suggested tasks</span>
<span class="kr">for</span> <span class="p">(</span>task.id <span class="kr">in</span> task.ids<span class="p">)</span> <span class="p">{</span> <span class="c1"># iterate over all tasks</span>
  task <span class="o">=</span> getOMLTask<span class="p">(</span>task.id<span class="p">)</span> <span class="c1"># download single OML task</span>
  data <span class="o">=</span> <span class="kp">as.data.frame</span><span class="p">(</span>task<span class="p">)</span> <span class="c1"># obtain raw data set</span>
</pre></div>
</details><h3 id="running-and-sharing-benchmarks">Running and sharing benchmarks<a class="headerlink" href="#running-and-sharing-benchmarks" title="Permanent link">&para;</a></h3>
<p>The code below demonstrates how OpenML benchmarking suites can be conveniently imported for benchmarking using the Python, Java and R APIs.</p>
<p>First, the list of tasks is downloaded as already illustrated above. Next, a specific algorithm (or pipeline) can be run on each of them. The OpenML API will automatically evaluate the algorithm using the pre-set train-test splits and store the predictions and scores in a run object. This run object can then be immediately published, pushing the results to the OpenML server, so that they can be compared against all others on the same benchmark set. Uploading results requires an OpenML API key, which can be found in your account details after logging into the OpenML website.</p>
<details class="note"><summary>REST</summary><p>Requires POST requests:<br />
<a href="https://www.openml.org/api_docs/#!/study/post_study_id_attach">Attaching a new run to a benchmark_study</a><br />
<a href="https://www.openml.org/api_docs/#!/study/post_study_id_detach">Detaching a run from benchmark_study</a>  </p></details><details class="note"><summary>Python example</summary><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">openml</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="n">openml</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">apikey</span> <span class="o">=</span> <span class="s1">&#39;FILL_IN_OPENML_API_KEY&#39;</span> <span class="c1"># set the OpenML Api Key</span>
<span class="n">benchmark_suite</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">get_study</span><span class="p">(</span><span class="s1">&#39;OpenML-CC18&#39;</span><span class="p">,</span><span class="s1">&#39;tasks&#39;</span><span class="p">)</span> <span class="c1"># obtain the benchmark suite</span>
<span class="c1"># build a sklearn classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">make_pipeline</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">Imputer</span><span class="p">(),</span>
                                     <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">())</span>
<span class="k">for</span> <span class="n">task_id</span> <span class="ow">in</span> <span class="n">benchmark_suite</span><span class="o">.</span><span class="n">tasks</span><span class="p">:</span> <span class="c1"># iterate over all tasks</span>
  <span class="n">task</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">get_task</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span> <span class="c1"># download the OpenML task</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">task</span><span class="o">.</span><span class="n">get_X_and_y</span><span class="p">()</span> <span class="c1"># get the data (not used in this example)</span>
  <span class="c1"># run classifier on splits (requires API key)</span>
  <span class="n">run</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">runs</span><span class="o">.</span><span class="n">run_model_on_task</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span>
  <span class="n">score</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">get_metric_score</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">)</span> <span class="c1"># print accuracy score</span>
  <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Data set: </span><span class="si">%s</span><span class="s1">; Accuracy: </span><span class="si">%0.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">()</span><span class="o">.</span><span class="n">name</span><span class="p">,</span><span class="n">score</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
  <span class="n">run</span><span class="o">.</span><span class="n">publish</span><span class="p">()</span> <span class="c1"># publish the experiment on OpenML (optional)</span>
  <span class="k">print</span><span class="p">(</span><span class="s1">&#39;URL for run: </span><span class="si">%s</span><span class="s1">/run/</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">openml</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">server</span><span class="p">,</span><span class="n">run</span><span class="o">.</span><span class="n">run_id</span><span class="p">))</span>
</pre></div>
</details><details class="note"><summary>Java example</summary><div class="highlight"><pre><span></span><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">runTasksAndUpload</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
  <span class="n">OpenmlConnector</span> <span class="n">openml</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OpenmlConnector</span><span class="o">();</span>
  <span class="n">openml</span><span class="o">.</span><span class="na">setApiKey</span><span class="o">(</span><span class="s">&quot;FILL_IN_OPENML_API_KEY&quot;</span><span class="o">);</span>
  <span class="c1">// obtain the benchmark suite</span>
  <span class="n">Study</span> <span class="n">benchmarksuite</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">studyGet</span><span class="o">(</span><span class="s">&quot;OpenML-CC18&quot;</span><span class="o">,</span> <span class="s">&quot;tasks&quot;</span><span class="o">);</span>
  <span class="n">Classifier</span> <span class="n">tree</span> <span class="o">=</span> <span class="k">new</span> <span class="n">REPTree</span><span class="o">();</span> <span class="c1">// build a Weka classifier</span>
  <span class="k">for</span> <span class="o">(</span><span class="n">Integer</span> <span class="n">taskId</span> <span class="o">:</span> <span class="n">benchmarksuite</span><span class="o">.</span><span class="na">getTasks</span><span class="o">())</span> <span class="o">{</span> <span class="c1">// iterate over all tasks</span>
    <span class="n">Task</span> <span class="n">t</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">taskGet</span><span class="o">(</span><span class="n">taskId</span><span class="o">);</span> <span class="c1">// download the OpenML task</span>
    <span class="n">Instances</span> <span class="n">d</span> <span class="o">=</span> <span class="n">InstancesHelper</span><span class="o">.</span><span class="na">getDatasetFromTask</span><span class="o">(</span><span class="n">openml</span><span class="o">,</span> <span class="n">t</span><span class="o">);</span> <span class="c1">// obtain the dataset</span>
    <span class="kt">int</span> <span class="n">runId</span> <span class="o">=</span> <span class="n">RunOpenmlJob</span><span class="o">.</span><span class="na">executeTask</span><span class="o">(</span><span class="n">openml</span><span class="o">,</span> <span class="k">new</span> <span class="n">WekaConfig</span><span class="o">(),</span> <span class="n">taskId</span><span class="o">,</span> <span class="n">tree</span><span class="o">);</span>
    <span class="n">Run</span> <span class="n">run</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">runGet</span><span class="o">(</span><span class="n">runId</span><span class="o">);</span>   <span class="c1">// retrieve the uploaded run</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</details><details class="note"><summary>R example</summary><div class="highlight"><pre><span></span><span class="kn">library</span><span class="p">(</span>OpenML<span class="p">)</span>
setOMLConfig<span class="p">(</span>apikey <span class="o">=</span> <span class="s">&#39;FILL_IN_OPENML_API_KEY&#39;</span><span class="p">)</span>
lrn <span class="o">=</span> makeLearner<span class="p">(</span><span class="s">&#39;classif.rpart&#39;</span><span class="p">)</span> <span class="c1"># construct a simple CART classifier</span>
task.ids <span class="o">=</span> getOMLStudy<span class="p">(</span><span class="s">&#39;OpenML-CC18&#39;</span><span class="p">)</span><span class="o">$</span>tasks<span class="o">$</span>task.id <span class="c1"># obtain the list of suggested tasks</span>
<span class="kr">for</span> <span class="p">(</span>task.id <span class="kr">in</span> task.ids<span class="p">)</span> <span class="p">{</span> <span class="c1"># iterate over all tasks</span>
  task <span class="o">=</span> getOMLTask<span class="p">(</span>task.id<span class="p">)</span> <span class="c1"># download single OML task</span>
  data <span class="o">=</span> <span class="kp">as.data.frame</span><span class="p">(</span>task<span class="p">)</span> <span class="c1"># obtain raw data set</span>
  run <span class="o">=</span> runTaskMlr<span class="p">(</span>task<span class="p">,</span> learner <span class="o">=</span> lrn<span class="p">)</span> <span class="c1"># run constructed learner</span>
  upload <span class="o">=</span> uploadOMLRun<span class="p">(</span>run<span class="p">)</span> <span class="c1"># upload and tag the run</span>
<span class="p">}</span>
</pre></div>
</details><h3 id="retrieving-runs-on-a-benchmarking-suites">Retrieving runs on a benchmarking suites:<a class="headerlink" href="#retrieving-runs-on-a-benchmarking-suites" title="Permanent link">&para;</a></h3>
<p>Once a benchmark suite has been created, the listing functions can be used to 
obtain all results on the benchmark suite. Note that there are several other
ways to select and bundle runs together. This will be featured in 
a separate article on reproducible benchmarks. </p>
<details class="note"><summary>REST (TODO)</summary><p><a href="https://www.openml.org/api/v1/xml/run/list/study/OpenML-CC18">https://www.openml.org/api/v1/xml/run/list/study/OpenML-CC18</a></p><p><a href="https://www.openml.org/api_docs/#!/run/get_run_list_filters">Check out the API docs</a></p></details><details class="note"><summary>Python example</summary><div class="highlight"><pre><span></span><span class="n">benchmark_suite</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">get_study</span><span class="p">(</span><span class="s1">&#39;OpenML-CC18&#39;</span><span class="p">,</span> <span class="s1">&#39;tasks&#39;</span><span class="p">)</span>
<span class="n">runs</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">runs</span><span class="o">.</span><span class="n">list_runs</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="n">benchmark_suite</span><span class="o">.</span><span class="n">tasks</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</details><details class="note"><summary>Java example</summary><div class="highlight"><pre><span></span><span class="kd">public</span> <span class="kt">void</span> <span class="nf">downloadResultsBenchmarkSuite</span><span class="o">()</span>  <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">Study</span> <span class="n">benchmarkSuite</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">studyGet</span><span class="o">(</span><span class="s">&quot;OpenML100&quot;</span><span class="o">,</span> <span class="s">&quot;tasks&quot;</span><span class="o">);</span>

    <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">filters</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TreeMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;&gt;();</span>
    <span class="n">filters</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;task&quot;</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">benchmarkSuite</span><span class="o">.</span><span class="na">getTasks</span><span class="o">()));</span>
    <span class="n">RunList</span> <span class="n">rl</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">runList</span><span class="o">(</span><span class="n">filters</span><span class="o">,</span> <span class="mi">200</span><span class="o">,</span> <span class="kc">null</span><span class="o">);</span>

    <span class="n">assertTrue</span><span class="o">(</span><span class="n">rl</span><span class="o">.</span><span class="na">getRuns</span><span class="o">().</span><span class="na">length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">);</span> 
<span class="o">}</span>
</pre></div>
</details><details class="note"><summary>R example</summary><div class="highlight"><pre><span></span>TODO
</pre></div>
</details><h3 id="creating-new-benchmark-suites">Creating new benchmark suites<a class="headerlink" href="#creating-new-benchmark-suites" title="Permanent link">&para;</a></h3>
<p>Additional OpenML benchmark suites can be created by defining the precise set of tasks, as well as a textual description. New datasets first need to be <a href="https://www.openml.org/new/data">registered on OpenML</a> and tasks need to be created on them.</p>
<p>We have provided <a href="https://github.com/openml/benchmark-suites">a GitHub repository</a> with additional tools and scripts to build new benchmark studies, e.g. to select all datasets adhering to strict conditions, and to analyse bencharking results.</p>
<details class="note"><summary>REST</summary><p>Requires POST requests:<br />
<a href="https://www.openml.org/api_docs/#!/study/post_study">Creating a benchmark suite</a>  </p></details><details class="note"><summary>Python example</summary><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">openml</span>

<span class="c1"># find 250 tasks that we are interested in, e.g., the tasks that have between</span>
<span class="c1"># 100 and 10000 instances and between 4 and 20 attributes</span>
<span class="n">tasks</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">list_tasks</span><span class="p">(</span><span class="n">number_instances</span><span class="o">=</span><span class="s1">&#39;100..10000&#39;</span><span class="p">,</span> <span class="n">number_features</span><span class="o">=</span><span class="s1">&#39;4..20&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
<span class="n">task_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tasks</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="c1"># create the benchmark suite</span>
<span class="c1"># the arguments are the alias, name, description, and list of task_ids, respectively.</span>
<span class="n">study</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">create_benchmark_suite</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="s2">&quot;MidSize Suite&quot;</span><span class="p">,</span> <span class="s2">&quot;illustrating how to create a benchmark suite&quot;</span><span class="p">,</span> <span class="n">task_ids</span><span class="p">)</span>
<span class="n">study_id</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">publish</span><span class="p">()</span>
</pre></div>
</details><details class="note"><summary>Java example</summary><div class="highlight"><pre><span></span><span class="kd">public</span> <span class="kt">void</span> <span class="nf">createBenchmarkSuite</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">OpenmlConnector</span> <span class="n">openml</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OpenmlConnector</span><span class="o">(</span><span class="s">&quot;FILL_IN_OPENML_API_KEY&quot;</span><span class="o">);</span>
    <span class="c1">// find 250 tasks that we are interested in, e.g., the tasks that have between</span>
    <span class="c1">// 100 and 10000 instances and between 4 and 20 attributes</span>
    <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">filtersOrig</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TreeMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;();</span>
    <span class="n">filtersOrig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;number_instances&quot;</span><span class="o">,</span> <span class="s">&quot;100..10000&quot;</span><span class="o">);</span>
    <span class="n">filtersOrig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;number_features&quot;</span><span class="o">,</span> <span class="s">&quot;4..20&quot;</span><span class="o">);</span>
    <span class="n">filtersOrig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;limit&quot;</span><span class="o">,</span> <span class="s">&quot;250&quot;</span><span class="o">);</span>
    <span class="n">Tasks</span> <span class="n">tasksOrig</span> <span class="o">=</span> <span class="n">client_write_test</span><span class="o">.</span><span class="na">taskList</span><span class="o">(</span><span class="n">filtersOrig</span><span class="o">);</span>

    <span class="c1">// create the study</span>
    <span class="n">Study</span> <span class="n">study</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Study</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">,</span> <span class="kc">null</span><span class="o">,</span> <span class="n">tasksOrig</span><span class="o">.</span><span class="na">getTaskIds</span><span class="o">(),</span> <span class="kc">null</span><span class="o">);</span>
    <span class="kt">int</span> <span class="n">studyId</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">studyUpload</span><span class="o">(</span><span class="n">study</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</details><details class="note"><summary>R example</summary><div class="highlight"><pre><span></span>TODO
</pre></div>
</details><h3 id="updating-a-benchmark-suite">Updating a benchmark suite<a class="headerlink" href="#updating-a-benchmark-suite" title="Permanent link">&para;</a></h3>
<p>You can add tasks to a benchmark suite, or remove them.</p>
<details class="note"><summary>REST</summary><p>Requires POST requests:<br />
<a href="https://www.openml.org/api_docs/#!/study/post_study_id_attach">Attaching a new task</a><br />
<a href="https://www.openml.org/api_docs/#!/study/post_study_id_detach">Detaching a task</a>  </p></details><details class="note"><summary>Python example</summary><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">openml</span>

<span class="c1"># find 250 tasks that we are interested in, e.g., the tasks that have between</span>
<span class="c1"># 100 and 10000 instances and between 4 and 20 attributes</span>
<span class="n">tasks</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">list_tasks</span><span class="p">(</span><span class="n">number_instances</span><span class="o">=</span><span class="s1">&#39;100..10000&#39;</span><span class="p">,</span> <span class="n">number_features</span><span class="o">=</span><span class="s1">&#39;4..20&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
<span class="n">task_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tasks</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="c1"># create the benchmark suite</span>
<span class="n">study</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">create_benchmark_suite</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="s2">&quot;MidSize Suite&quot;</span><span class="p">,</span> <span class="s2">&quot;illustrating how to create a benchmark suite&quot;</span><span class="p">,</span> <span class="n">task_ids</span><span class="p">)</span>
<span class="n">study_id</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">publish</span><span class="p">()</span>

<span class="c1"># download the study from the server, for verification purposes</span>
<span class="n">study</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">get_study</span><span class="p">(</span><span class="n">study_id</span><span class="p">)</span>

<span class="c1"># until the benchmark suite is activated, we can also add some more tasks. Search for the letter dataset:</span>
<span class="n">tasks_new</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">list_tasks</span><span class="p">(</span><span class="n">data_name</span><span class="o">=</span><span class="s1">&#39;letter&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">task_ids_new</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tasks_new</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">attach_to_study</span><span class="p">(</span><span class="n">study_id</span><span class="p">,</span> <span class="n">task_ids_new</span><span class="p">)</span>

<span class="c1"># or even remove these again</span>
<span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">detach_from_study</span><span class="p">(</span><span class="n">study_id</span><span class="p">,</span> <span class="n">task_ids_new</span><span class="p">)</span>

<span class="c1"># redownload the study</span>
<span class="n">study_prime</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="n">study</span><span class="o">.</span><span class="n">get_study</span><span class="p">(</span><span class="n">study_id</span><span class="p">)</span>

<span class="k">assert</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">tasks</span> <span class="o">==</span> <span class="n">study_prime</span><span class="o">.</span><span class="n">tasks</span><span class="p">)</span>
<span class="k">assert</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">data</span> <span class="o">==</span> <span class="n">study_prime</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</details><details class="note"><summary>Java example</summary><div class="highlight"><pre><span></span><span class="kd">public</span> <span class="kt">void</span> <span class="nf">attachDetachStudy</span><span class="o">()</span>  <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">OpenmlConnector</span> <span class="n">openml</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OpenmlConnector</span><span class="o">(</span><span class="s">&quot;FILL_IN_OPENML_API_KEY&quot;</span><span class="o">);</span>
    <span class="c1">// find 250 tasks that we are interested in, e.g., the tasks that have between</span>
    <span class="c1">// 100 and 10000 instances and between 4 and 20 attributes</span>
    <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">filtersOrig</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TreeMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;();</span>
    <span class="n">filtersOrig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;number_instances&quot;</span><span class="o">,</span> <span class="s">&quot;100..10000&quot;</span><span class="o">);</span>
    <span class="n">filtersOrig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;number_features&quot;</span><span class="o">,</span> <span class="s">&quot;4..20&quot;</span><span class="o">);</span>
    <span class="n">filtersOrig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;limit&quot;</span><span class="o">,</span> <span class="s">&quot;250&quot;</span><span class="o">);</span>
    <span class="n">Tasks</span> <span class="n">tasksOrig</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">taskList</span><span class="o">(</span><span class="n">filtersOrig</span><span class="o">);</span>

    <span class="c1">// create the study</span>
    <span class="n">Study</span> <span class="n">study</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Study</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">,</span> <span class="kc">null</span><span class="o">,</span> <span class="n">tasksOrig</span><span class="o">.</span><span class="na">getTaskIds</span><span class="o">(),</span> <span class="kc">null</span><span class="o">);</span>
    <span class="kt">int</span> <span class="n">studyId</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">studyUpload</span><span class="o">(</span><span class="n">study</span><span class="o">);</span>

    <span class="c1">// until the benchmark suite is activated, we can also add some more tasks. Search for the letter dataset:</span>
    <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">filtersAdd</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TreeMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;();</span>
    <span class="n">filtersAdd</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;data_name&quot;</span><span class="o">,</span> <span class="s">&quot;letter&quot;</span><span class="o">);</span>
    <span class="n">filtersAdd</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;limit&quot;</span><span class="o">,</span> <span class="s">&quot;1&quot;</span><span class="o">);</span>
    <span class="n">Tasks</span> <span class="n">tasksAdd</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">taskList</span><span class="o">(</span><span class="n">filtersAdd</span><span class="o">);</span>
    <span class="n">openml</span><span class="o">.</span><span class="na">studyAttach</span><span class="o">(</span><span class="n">studyId</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">tasksAdd</span><span class="o">.</span><span class="na">getTaskIds</span><span class="o">()));</span>

    <span class="c1">// or even remove these again</span>
    <span class="n">openml</span><span class="o">.</span><span class="na">studyDetach</span><span class="o">(</span><span class="n">studyId</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">tasksAdd</span><span class="o">.</span><span class="na">getTaskIds</span><span class="o">()));</span>

    <span class="c1">// download the study</span>
    <span class="n">Study</span> <span class="n">studyDownloaded</span> <span class="o">=</span> <span class="n">openml</span><span class="o">.</span><span class="na">studyGet</span><span class="o">(</span><span class="n">studyId</span><span class="o">);</span>
    <span class="n">assertArrayEquals</span><span class="o">(</span><span class="n">tasksOrig</span><span class="o">.</span><span class="na">getTaskIds</span><span class="o">(),</span> <span class="n">studyDownloaded</span><span class="o">.</span><span class="na">getTasks</span><span class="o">());</span>
<span class="o">}</span>
</pre></div>
</details><details class="note"><summary>R example</summary><div class="highlight"><pre><span></span>TODO
</pre></div>
</details><h2 id="further-code-examples-and-use-cases">Further code examples and use cases<a class="headerlink" href="#further-code-examples-and-use-cases" title="Permanent link">&para;</a></h2>
<p>As mentioned above, we host <a href="https://github.com/openml/benchmark-suites">a GitHub repository</a> with additional tools and scripts to easily create and use new benchmark studies. It includes:</p>
<ul>
<li>A Jupyter Notebook that builds a new benchmark suite with datasets that adhere to strict and complex conditions, as well as automated tests to remove tasks that are too easy for proper benchmarking.</li>
<li>A Jupyter Notebook that shows how to pull in the latest state-of-the-art results for any of the benchmark suites</li>
<li>A Jupyter Notebook that does a detailed analysis of all results in a benchmark suite, and an example run on the OpenML-CC18. It includes a wide range of plots and rankings to get a deeper insight into the benchmark results.</li>
<li>Scripts in Python and R to facilitate common subtasks.</li>
</ul>
<p>We very much welcome new scripts and notebooks, or improvements to the existing ones, that help others to create benchmark suites and analyse benchmarking results.</p>
<h2 id="list-of-benchmarking-suites">List of benchmarking suites<a class="headerlink" href="#list-of-benchmarking-suites" title="Permanent link">&para;</a></h2>
<h3 id="openml-cc18">OpenML-CC18<a class="headerlink" href="#openml-cc18" title="Permanent link">&para;</a></h3>
<p>The <a href="https://www.openml.org/s/99">OpenML-CC18</a> suite contains all OpenML datasets from mid-2018 that satisfy a large set of clear requirements for thorough yet practical benchmarking. It includes datasets frequently used in benchmarks published over the last years, so it can be used as a drop-in replacement for many benchmarking setups.</p>
<p><a href="https://www.openml.org/search?q=tags.tag%3Astudy_99&amp;type=data&amp;table=1&amp;size=73">List of datasets and properties</a></p>
<p>The suite is defined as the set of all verified OpenML datasets that satisfy the following requirements:</p>
<ul>
<li>the number of observations are between 500 and 100000 to focus on medium-sized datasets, that are not too small and not too big,</li>
<li>the number of features does not exceed 5000 features to keep the runtime of algorithms low,</li>
<li>the target attribute has at least two classes</li>
<li>have classes with less than 20 observations</li>
<li>the ratio of the minority class and the majority class is above 0.05, to eliminate highly imbalanced datasets which require special treatment for both algorithms and evaluation measures.</li>
</ul>
<p>We excluded datasets which:</p>
<ul>
<li>are artificially generated (not to confuse with simulated)</li>
<li>cannot be randomized via a 10-fold cross-validation due to grouped samples or because they are time series or data streams</li>
<li>are a subset of a larger dataset</li>
<li>have no source or reference available</li>
<li>can be perfectly classified by a single attribute or a decision stump</li>
<li>allow a decision tree to achieve 100% accuracy on a 10-fold cross-validation task</li>
<li>have more than 5000 features after one-hot-encoding categorical features</li>
<li>are created by binarization of regression tasks or multiclass classification tasks, or</li>
<li>are sparse data (e.g., text mining data sets)</li>
</ul>
<details class="note"><summary>Detailed motivation of these decisions</summary><p>We chose the CC18 datasets to allow for practical benchmarking based on the characteristics that might be problematic based on our experience, and to avoid common pitfalls that may invalidate benchmark studies:  </p><ul><li>We used at least 500 data points to allow performing cross-validation while still having a large-enough test split.</li><li>We limited the datasets to 100.000 data points to allow the algorithms to train machine learning models in a reasonable amount of time.</li><li>We limited the number of features to 5000 to allow the usage of algorithms which scale unfavourably in the number of features. This limitation, together with the two limitations above aims to allow running all “standard” machine learning algorithms (naive bayes, linear models, support vector machines, tree-based ensemble methods and neural networks) on the benchmark suite.</li><li>We required each dataset to have at least two classes to be able to work in a supervised classification setting.</li><li>We require each class to have at least 20 observations to be able to perform stratified cross-validation where there is at least one observation from each class in each split. We have found that not having all classes present in all training and test sets can make several machine learning packages fail.</li><li>We require a certain balancedness (ratio of minority class to majority class) to prevent cases where only predicting the majority class would be beneficial. This is most likely the restriction which is most debatable, but we found it very helpful to apply a large set of machine learning algorithms across several libraries to the study. We expect that future studies focus more on imbalanced datasets. </li></ul><p>Furthermore, we aimed to have the dataset collection as general as possible, rule out as few algorithms as possible and have it usable as easily as possible:</p><ul><li>We strived to remove artificial datasets as they, for example, come from textbooks and it is hard to reliably assess their difficulty. We admit that there is a blurred line between artificial and simulated datasets and do not have a perfect distinction between them (for example, a lot of phenomena can be simulated, but the outcome might be like a simple, artificial dataset). Therefore, we removed datasets if we were in doubt of whether they are simulated or artificial. </li><li>We removed datasets which require grouped sampling because they are time series or data streams which should be treated with special care by machine learning algorithms (i.e., taking the time aspect into account). To be on the safe side, we also removed datasets where each sample constitutes a single data stream.</li><li>We removed datasets which are a subset of larger datasets. Allowing subsets would be very subjective as there is no objective choice of a dataset subset size or a subset of the variables or classes. Therefore, creating dataset subsets would open a Pandora’s Box.</li><li>We removed datasets which have no source or reference available to potentially learn more about these datasets if we observe unexpected behavior in future studies. In contrast, we would not be able to learn more about the background of a dataset which has no description and publication attached, leaving us with a complete black box.</li><li>We removed datasets which can be perfectly classified by a single attribute or a decision stump as they do not allow to meaningfully compare machine learning algorithms (they all achieve 100% accuracy unless the hyperparameters are set in a bogus way).</li><li>We removed datasets where a decision tree could achieve 100% accuracy on a 10-fold cross-validation task to remove datasets which can be solved by a simple algorithm which is prone to overfitting training data. We found that this is a good indicator of too easy datasets. Obviously, other datasets will appear easy for several algorithms, and we aim to learn more about the characteristics of such datasets in future studies.</li><li>We removed datasets which have more than 5000 features after one-hot-encoding categorical features. One-hot-encoding is the most frequent way to deal with categorical variables across the different machine learning libraries MLR, scikit-learn and WEKA. In order to limit the number of features to 5000 as explained above, we imposed the additional constraint that this should be counted after one-hot-encoding to allow wide applicability of the benchmark suite.</li><li>We removed datasets which were created by binarization of regression tasks or multiclass classification task for similar reasons as for forbidding dataset subsets.</li><li>We did not include sparse datasets because not all machine learning libraries (i.e., all machine learning models) can handle them gracefully, which is in contrast to our goal which is wide applicability.</li></ul></details><h3 id="openml100">OpenML100<a class="headerlink" href="#openml100" title="Permanent link">&para;</a></h3>
<p>The <a href="https://www.openml.org/s/14">OpenML100</a> was a predecessor of the OpenML-CC18, consisting of <a href="https://www.openml.org/search?q=tags.tag%3AOpenML100&amp;type=data&amp;table=1&amp;size=100">100 classification datasets</a></a>. We recommend that you use the <strong>OpenML-CC18</strong> instead, because the OpenML100 suffers from some teething issues in the design of benchmark suites. For instance, it contains several datasets that are too easy to model with today's machine learning algorithms, as well as datasets that represent time series analysis problems. These do not invalidate benchmarks run on the OpenML100, but may obfuscate the interpretation of results. The 'OpenML-CC18' handle is also more descriptive and allows easier versioning.
The OpenML100 was first published in the Arxiv preprint <a href="https://arxiv.org/abs/1708.03731">OpenML Benchmarking Suites and the OpenML100</a>.</p>
<p><a href="https://www.openml.org/s/14">List of datasets and properties</a></p>
<p>For reference, the OpenML100 included datasets satisfying the following requirements:</p>
<ul>
<li>the number of observations are between 500 and 100000 to focus on medium-sized datasets, that are not too small for proper training and not too big for practical experimentation</li>
<li>the number of features does not exceed 5000 features to keep the runtime of algorithms low</li>
<li>the target attribute has at least two classes</li>
<li>he ratio of the minority class and the majority class is above 0.05 to eliminate highly imbalanced datasets that would obfuscate a clear analysis</li>
</ul>
<p>It excluded datasets which:</p>
<ul>
<li>cannot be randomized via a 10-fold cross-validation due to grouped samples</li>
<li>have an unknown origin or no clearly defined task</li>
<li>are variants of other datasets (e.g. binarized regression tasks)</li>
<li>include sparse data (e.g., text mining data sets)</li>
</ul>
<h2 id="need-help">Need help?<a class="headerlink" href="#need-help" title="Permanent link">&para;</a></h2>
<p>We are happy to answer to any suggestion or question you may have. For general questions or issues, please open an issue in the <a href="https://github.com/openml/benchmark-suites">benchmarking issue tracker</a>. If the issue lies with one of the language-specific bindings, please post an issue <a href="https://docs.openml.org/developers/">in the appropriate issue tracker</a>.</p>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../Core-team/" title="Core team" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Core team
              </span>
            </div>
          </a>
        
        
          <a href="../altmetrics/" title="Altmetrics" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Altmetrics
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.62cfdabc.js"></script>
      
      <script>app.initialize({version:"0.17.3",url:{base:".."}})</script>
      
        <script src="../js/extra.js"></script>
      
        <script src="../search/require.js"></script>
      
        <script src="../search/search.js"></script>
      
    
    
      
    
  </body>
</html>